#!/usr/bin/env node

const fs = require('fs');
const path = require('path');
const { default: fetch } = require('node-fetch');
const FormData = require('form-data');

async function testSyncTranscription() {
  console.log('ğŸ§ª ×‘×“×™×§×” ×¡×™× ×›×¨×•× ×™×ª (×œ×œ× webhook) ×¢× ×§×•×‘×¥ ×”×§×œ×˜...\n');

  const audioFilePath = path.join(__dirname, 'test_input', 'audio1436646319.m4a');
  
  if (!fs.existsSync(audioFilePath)) {
    console.error('âŒ ×§×•×‘×¥ ×”×©××¢ ×œ× × ××¦×:', audioFilePath);
    return;
  }

  console.log('ğŸ“ × ××¦× ×§×•×‘×¥ ×©××¢:', audioFilePath);
  const stats = fs.statSync(audioFilePath);
  console.log('ğŸ“Š ×’×•×“×œ ×§×•×‘×¥:', (stats.size / 1024 / 1024).toFixed(2), 'MB');

  const apiKey = 'sk_63273dc2fb5b982fa618983c924954749908381a638d1566';

  try {
    // ×™×¦×™×¨×ª ×§×˜×¢ ×§×˜×Ÿ ×œ×‘×“×™×§×” (30 ×©× ×™×•×ª)
    console.log('\n1. ×™×•×¦×¨ ×§×˜×¢ ×§×˜×Ÿ ×œ×‘×“×™×§×”...');
    
    const { execSync } = require('child_process');
    const testSegmentPath = path.join(__dirname, 'temp_test_30sec.mp3');
    
    try {
      // ×™×¦×™×¨×ª ×§×˜×¢ ×©×œ 30 ×©× ×™×•×ª
      console.log('   ğŸ”„ ×—×•×ª×š 30 ×©× ×™×•×ª ×¨××©×•× ×•×ª...');
      execSync(`ffmpeg -i "${audioFilePath}" -t 30 -acodec mp3 -ar 16000 -ac 1 -y "${testSegmentPath}"`, { 
        stdio: 'pipe' 
      });
      
      const segmentStats = fs.statSync(testSegmentPath);
      console.log('   âœ… × ×•×¦×¨ ×§×˜×¢:', (segmentStats.size / 1024).toFixed(2), 'KB');
      
      // ×©×œ×™×—×” ×œ-ElevenLabs (××¦×‘ ×¡×™× ×›×¨×•× ×™ - ×œ×œ× webhook)
      console.log('\n2. ×©×•×œ×— ×œ-ElevenLabs (××¦×‘ ×¡×™× ×›×¨×•× ×™)...');
      
      const formData = new FormData();
      formData.append('file', fs.createReadStream(testSegmentPath));
      formData.append('model_id', 'scribe_v1');
      // ×œ× ×©×•×œ×—×™× webhook parameter - ×–×” ×™×”×™×” ×¡×™× ×›×¨×•× ×™
      
      console.log('   ğŸ“¤ ××¢×œ×” ×•××ª××œ×œ...');
      
      const response = await fetch('https://api.elevenlabs.io/v1/speech-to-text', {
        method: 'POST',
        headers: {
          'xi-api-key': apiKey,
          ...formData.getHeaders()
        },
        body: formData
      });

      if (response.ok) {
        const result = await response.json();
        console.log('   âœ… ×ª××œ×•×œ ×”×¦×œ×™×—!');
        console.log('   ğŸ“ ×ª×•×¦××” (30 ×©× ×™×•×ª ×¨××©×•× ×•×ª):');
        console.log('   â”€'.repeat(60));
        console.log('   ' + (result.text || '××™×Ÿ ×˜×§×¡×˜ ×ª××œ×•×œ'));
        console.log('   â”€'.repeat(60));
        
        if (result.language_code) {
          console.log('   ğŸŒ ×©×¤×” ××–×•×”×”:', result.language_code);
        }
        
        console.log('\nğŸ¯ ×”××¡×§× ×”: ElevenLabs API ×¢×•×‘×“ ××¦×•×™×Ÿ!');
        console.log('ğŸ’¡ ×›×“×™ ×œ×ª××œ×œ ××ª ×”×§×•×‘×¥ ×”××œ× (1.8 ×©×¢×•×ª):');
        console.log('   1. ×¦×¨×™×š ×œ×—×œ×§ ×œ×§×˜×¢×™× ×©×œ 15 ×“×§×•×ª');
        console.log('   2. ×œ×©×œ×•×— ×›×œ ×§×˜×¢ ×‘× ×¤×¨×“');
        console.log('   3. ×œ×—×‘×¨ ××ª ×”×ª×•×¦××•×ª');
        console.log('   4. ××• ×œ×”×©×ª××© ×‘-webhook mode ×¢× ngrok');
        
      } else {
        const errorText = await response.text();
        console.error('   âŒ ×ª××œ×•×œ × ×›×©×œ:', response.status, response.statusText);
        console.error('   ğŸ“„ ×¤×¨×˜×™ ×©×’×™××”:', errorText);
        
        if (response.status === 413) {
          console.log('   ğŸ’¡ ×”×§×•×‘×¥ ×’×“×•×œ ××“×™ - × ×¡×” ×§×˜×¢ ×§×¦×¨ ×™×•×ª×¨');
        } else if (response.status === 401) {
          console.log('   ğŸ’¡ ×‘×¢×™×” ×¢× API key');
        } else if (response.status === 422) {
          console.log('   ğŸ’¡ ×¤×•×¨××˜ ×§×•×‘×¥ ×œ× × ×ª××š ××• ×‘×¢×™×” ××—×¨×ª');
        }
      }
      
      // × ×™×§×•×™
      if (fs.existsSync(testSegmentPath)) {
        fs.unlinkSync(testSegmentPath);
        console.log('   ğŸ§¹ ×§×•×‘×¥ ×–×× ×™ × ××—×§');
      }
      
    } catch (ffmpegError) {
      console.log('   âš ï¸  ffmpeg ×œ× ×–××™×Ÿ');
      console.log('   ğŸ’¡ ×œ×”×ª×§× ×”: brew install ffmpeg');
      console.log('   ğŸ”„ ×× ×¡×” ×¢× ×”×§×•×‘×¥ ×”××œ× (×¢×œ×•×œ ×œ×”×™×›×©×œ)...');
      
      // × ×™×¡×™×•×Ÿ ×¢× ×”×§×•×‘×¥ ×”××œ×
      const formData = new FormData();
      formData.append('file', fs.createReadStream(audioFilePath));
      formData.append('model_id', 'scribe_v1');
      
      const response = await fetch('https://api.elevenlabs.io/v1/speech-to-text', {
        method: 'POST',
        headers: {
          'xi-api-key': apiKey,
          ...formData.getHeaders()
        },
        body: formData
      });

      if (response.ok) {
        const result = await response.json();
        console.log('   âœ… ×ª××œ×•×œ ×”×¦×œ×™×— (××¤×ª×™×¢!)');
        console.log('   ğŸ“ ×ª×•×¦××”:', result.text?.substring(0, 200) + '...');
      } else {
        console.error('   âŒ ×ª××œ×•×œ × ×›×©×œ:', response.status);
        console.log('   ğŸ’¡ ×”×§×•×‘×¥ ×’×“×•×œ ××“×™ - ×¦×¨×™×š ×œ×—×œ×§ ×œ×§×˜×¢×™×');
      }
    }

  } catch (error) {
    console.error('âŒ ×©×’×™××”:', error.message);
  }

  console.log('\nğŸ“‹ ×¡×™×›×•×:');
  console.log('âœ… ElevenLabs API ×¢×•×‘×“');
  console.log('âš ï¸  ×”×§×•×‘×¥ ×’×“×•×œ ××“×™ ×œ×ª××œ×•×œ ×™×©×™×¨');
  console.log('ğŸ”§ ×œ××¤×œ×™×§×¦×™×” ×”××œ××” ×¦×¨×™×š:');
  console.log('   1. Supabase ××•×’×“×¨ (××¡×“ × ×ª×•× ×™× + storage)');
  console.log('   2. ngrok ×œwebhook (××• ××¦×‘ ×¡×™× ×›×¨×•× ×™)');
  console.log('   3. ×—×œ×•×§×” ×œ×§×˜×¢×™× ×©×œ 15 ×“×§×•×ª');
}

testSyncTranscription();